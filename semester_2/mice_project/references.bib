@book{MLwithR,
series = {Community experience distilled},
abstract = {R gives you access to the cutting-edge software you need to prepare data for machine learning. No previous knowledge required – this book will take you methodically through every stage of applying machine learning. Harness the power of R for statistical computing and data science Use R to apply common machine learning algorithms with real-world applications Prepare, examine, and visualize data for analysis Understand how to choose between machine learning models Packed with clear instructions to explore, forecast, and classify data In Detail Machine learning, at its core, is concerned with transforming data into actionable knowledge. This fact makes machine learning well-suited to the present-day era of "big data" and "data science". Given the growing prominence of R—a cross-platform, zero-cost statistical programming environment—there has never been a better time to start applying machine learning. Whether you are new to data science or a veteran, machine learning with R offers a powerful set of methods for quickly and easily gaining insight from your data. "Machine Learning with R" is a practical tutorial that uses hands-on examples to step through real-world application of machine learning. Without shying away from the technical details, we will explore Machine Learning with R using clear and practical examples. Well-suited to machine learning beginners or those with experience. Explore R to find the answer to all of your questions. How can we use machine learning to transform data into action? Using practical examples, we will explore how to prepare data for analysis, choose a machine learning method, and measure the success of the process. We will learn how to apply machine learning methods to a variety of common tasks including classification, prediction, forecasting, market basket analysis, and clustering. By applying the most effective machine learning methods to real-world problems, you will gain hands-on experience that will transform the way you think about data. "Machine Learning with R" will provide you with the analytical tools you need to quickly gain insight from complex data.},
publisher = {Packt Publishing},
isbn = {1-68015-358-7},
year = {2013},
title = {Machine learning with R},
edition = {1st edition.},
language = {eng},
address = {Birmingham},
author = {Lantz, Brett},
keywords = {Machine learning -- Statistical methods -- Handbooks manuals etc; R (Computer program language) -- Handbooks manuals etc; Programming languages (Electronic computers); Electronic data processing; Languages Artificial; Domain-specific programming languages; Artificial intelligence; Machine theory},
}

@article{missingDataNumber,
issn = {2193-1801},
abstract = {The impact of missing data on quantitative research can be serious, leading to biased estimates of parameters, loss of information, decreased statistical power, increased standard errors, and weakened generalizability of findings. In this paper, we discussed and demonstrated three principled missing data methods: multiple imputation, full information maximum likelihood, and expectation-maximization algorithm, applied to a real-world data set. Results were contrasted with those obtained from the complete data set and from the listwise deletion method. The relative merits of each method are noted, along with common features they share. The paper concludes with an emphasis on the importance of statistical assumptions, and recommendations for researchers. Quality of research will be enhanced if (a) researchers explicitly acknowledge missing data problems and the conditions under which they occurred, (b) principled methods are employed to handle missing data, and (c) the appropriate treatment of missing data is incorporated into review standards of manuscripts submitted for publication.},
journal = {SpringerPlus},
pages = {1--17},
volume = {2},
publisher = {Springer International Publishing},
number = {1},
year = {2013},
title = {Principled missing data methods for researchers},
copyright = {Dong and Peng; licensee Springer. 2013. This article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
language = {eng},
address = {Cham},
author = {Dong, Yiran and Peng, Chao-Ying Joanne},
keywords = {Artificial intelligence ; Complete data ; Data mining ; Fiml ; Generalizability theory ; Humanities and Social Sciences ; Imputation (statistics) ; Listwise deletion ; Machine learning ; Mar ; Mcar ; Medicine ; Methodology ; Missing data ; Mnar ; multidisciplinary ; Science ; Science (multidisciplinary) ; Social Sciences ; Standard error ; Statistical assumption ; Statistical power},
}

@article{mcarTest,
author = {Cheng Li},
title ={Little's Test of Missing Completely at Random},

journal = {The Stata Journal},
volume = {13},
number = {4},
pages = {795-809},
year = {2013},
doi = {10.1177/1536867X1301300407},

URL = { 
    
        https://doi.org/10.1177/1536867X1301300407
    
    

},
eprint = { 
    
        https://doi.org/10.1177/1536867X1301300407
    
    

}
,
    abstract = { In missing-data analysis, Little's test (1988, Journal of the American Statistical Association 83: 1198–1202) is useful for testing the assumption of missing completely at random for multivariate, partially observed quantitative data. I introduce the mcartest command, which implements Little's missing completely at random test and its extension for testing the covariate-dependent missingness. The command also includes an option to perform the likelihood-ratio test with adjustment for unequal variances. I illustrate the use of mcartest through an example and evaluate the finite-sample performance of these tests in simulation studies. }
}

@misc{proportionPlots,
  author = {Nicole Erler},
  title = {Function to create barplot comparing observed and imputed values from a mids object},
  year = {2019},
  publisher = {Nicole Erler via github},
  howpublished = {\url{https://gist.github.com/NErler/0d00375da460dd33839b98faeee2fdab}},
  note = "[Online, accessed 7th April 2024]"
}